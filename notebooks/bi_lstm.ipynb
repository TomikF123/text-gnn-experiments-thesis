{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import torch.optim as optim  \n",
    "import torch.nn.functional as F  \n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_all = pd.read_csv('data/mr_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idk'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_all.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 :::: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n"
     ]
    }
   ],
   "source": [
    "print(len(mr_all[\"text\"][0]),\"::::\",mr_all[\"text\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"./data\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_stopwords=True):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])  # Remove punctuation\n",
    "    tokens = text.split()  # Tokenize\n",
    "\n",
    "    if remove_stopwords:\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens  # return as list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mr_all[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_all[\"tokens\"] = mr_all[\"text\"].apply(preprocess_text, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 :::: ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'centurys', 'new', 'conan', 'and', 'that', 'hes', 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', 'jeanclaud', 'van', 'damme', 'or', 'steven', 'segal']\n"
     ]
    }
   ],
   "source": [
    "print(len(mr_all[\"tokens\"][0]),\"::::\",mr_all[\"tokens\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 197296, Unique words: 20492\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in mr_all[\"tokens\"] for word in tokens]\n",
    "print(f\"Total tokens: {len(all_words)}, Unique words: {len(set(all_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mr_all[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'rock',\n",
       " 'is',\n",
       " 'destined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " '21st',\n",
       " 'centurys',\n",
       " 'new',\n",
       " 'conan',\n",
       " 'and',\n",
       " 'that',\n",
       " 'hes',\n",
       " 'going',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'splash',\n",
       " 'even',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'arnold',\n",
       " 'schwarzenegger',\n",
       " 'jeanclaud',\n",
       " 'van',\n",
       " 'damme',\n",
       " 'or',\n",
       " 'steven',\n",
       " 'segal',\n",
       " 'the',\n",
       " 'gorgeously',\n",
       " 'elaborate',\n",
       " 'continuation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lord',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rings',\n",
       " 'trilogy',\n",
       " 'is',\n",
       " 'so',\n",
       " 'huge',\n",
       " 'that',\n",
       " 'a',\n",
       " 'column',\n",
       " 'of',\n",
       " 'words',\n",
       " 'cannot',\n",
       " 'adequately',\n",
       " 'describe',\n",
       " 'cowriterdirector',\n",
       " 'peter',\n",
       " 'jacksons',\n",
       " 'expanded',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'j',\n",
       " 'r',\n",
       " 'r',\n",
       " 'tolkiens',\n",
       " 'middleearth',\n",
       " 'effective',\n",
       " 'but',\n",
       " 'tootepid',\n",
       " 'biopic',\n",
       " 'if',\n",
       " 'you',\n",
       " 'sometimes',\n",
       " 'like',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'to',\n",
       " 'have',\n",
       " 'fun',\n",
       " 'wasabi',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'place',\n",
       " 'to',\n",
       " 'start',\n",
       " 'emerges',\n",
       " 'as',\n",
       " 'something',\n",
       " 'rare',\n",
       " 'an',\n",
       " 'issue',\n",
       " 'movie',\n",
       " 'thats',\n",
       " 'so',\n",
       " 'honest',\n",
       " 'and',\n",
       " 'keenly',\n",
       " 'observed',\n",
       " 'that',\n",
       " 'it',\n",
       " 'doesnt',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'one',\n",
       " 'the',\n",
       " 'film',\n",
       " 'provides',\n",
       " 'some',\n",
       " 'great',\n",
       " 'insight',\n",
       " 'into',\n",
       " 'the',\n",
       " 'neurotic',\n",
       " 'mindset',\n",
       " 'of',\n",
       " 'all',\n",
       " 'comics',\n",
       " 'even',\n",
       " 'those',\n",
       " 'who',\n",
       " 'have',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'absolute',\n",
       " 'top',\n",
       " 'of',\n",
       " 'the',\n",
       " 'game',\n",
       " 'offers',\n",
       " 'that',\n",
       " 'rare',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'entertainment',\n",
       " 'and',\n",
       " 'education',\n",
       " 'perhaps',\n",
       " 'no',\n",
       " 'picture',\n",
       " 'ever',\n",
       " 'made',\n",
       " 'has',\n",
       " 'more',\n",
       " 'literally',\n",
       " 'showed',\n",
       " 'that',\n",
       " 'the',\n",
       " 'road',\n",
       " 'to',\n",
       " 'hell',\n",
       " 'is',\n",
       " 'paved',\n",
       " 'with',\n",
       " 'good',\n",
       " 'intentions',\n",
       " 'steers',\n",
       " 'turns',\n",
       " 'in',\n",
       " 'a',\n",
       " 'snappy',\n",
       " 'screenplay',\n",
       " 'that',\n",
       " 'curls',\n",
       " 'at',\n",
       " 'the',\n",
       " 'edges',\n",
       " 'its',\n",
       " 'so',\n",
       " 'clever',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'hate',\n",
       " 'it',\n",
       " 'but',\n",
       " 'he',\n",
       " 'somehow',\n",
       " 'pulls',\n",
       " 'it',\n",
       " 'off',\n",
       " 'take',\n",
       " 'care',\n",
       " 'of',\n",
       " 'my',\n",
       " 'cat',\n",
       " 'offers',\n",
       " 'a',\n",
       " 'refreshingly',\n",
       " 'different',\n",
       " 'slice',\n",
       " 'of',\n",
       " 'asian',\n",
       " 'cinema',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'film',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'seeing',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'singing',\n",
       " 'heads',\n",
       " 'and',\n",
       " 'all',\n",
       " 'what',\n",
       " 'really',\n",
       " 'surprises',\n",
       " 'about',\n",
       " 'wisegirls',\n",
       " 'is',\n",
       " 'its',\n",
       " 'lowkey',\n",
       " 'quality',\n",
       " 'and',\n",
       " 'genuine',\n",
       " 'tenderness',\n",
       " 'wendigo',\n",
       " 'is',\n",
       " 'why',\n",
       " 'we',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cinema',\n",
       " 'to',\n",
       " 'be',\n",
       " 'fed',\n",
       " 'through',\n",
       " 'the',\n",
       " 'eye',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'familyoriented',\n",
       " 'fantasyadventure',\n",
       " 'movies',\n",
       " 'ever',\n",
       " 'ultimately',\n",
       " 'it',\n",
       " 'ponders',\n",
       " 'the',\n",
       " 'reasons',\n",
       " 'we',\n",
       " 'need',\n",
       " 'stories',\n",
       " 'so',\n",
       " 'much',\n",
       " 'an',\n",
       " 'utterly',\n",
       " 'compelling',\n",
       " 'who',\n",
       " 'wrote',\n",
       " 'it',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'reputation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'famous',\n",
       " 'author',\n",
       " 'who',\n",
       " 'ever',\n",
       " 'lived',\n",
       " 'comes',\n",
       " 'into',\n",
       " 'question',\n",
       " 'illuminating',\n",
       " 'if',\n",
       " 'overly',\n",
       " 'talky',\n",
       " 'documentary',\n",
       " 'a',\n",
       " 'masterpiece',\n",
       " 'four',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'making',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'ripe',\n",
       " 'enrapturing',\n",
       " 'beauty',\n",
       " 'will',\n",
       " 'tempt',\n",
       " 'those',\n",
       " 'willing',\n",
       " 'to',\n",
       " 'probe',\n",
       " 'its',\n",
       " 'inscrutable',\n",
       " 'mysteries',\n",
       " 'offers',\n",
       " 'a',\n",
       " 'breath',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fresh',\n",
       " 'air',\n",
       " 'of',\n",
       " 'true',\n",
       " 'sophistication',\n",
       " 'a',\n",
       " 'thoughtful',\n",
       " 'provocative',\n",
       " 'insistently',\n",
       " 'humanizing',\n",
       " 'film',\n",
       " 'with',\n",
       " 'a',\n",
       " 'cast',\n",
       " 'that',\n",
       " 'includes',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'top',\n",
       " 'actors',\n",
       " 'working',\n",
       " 'in',\n",
       " 'independent',\n",
       " 'film',\n",
       " 'lovely',\n",
       " 'amazing',\n",
       " 'involves',\n",
       " 'us',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'so',\n",
       " 'incisive',\n",
       " 'so',\n",
       " 'bleakly',\n",
       " 'amusing',\n",
       " 'about',\n",
       " 'how',\n",
       " 'we',\n",
       " 'go',\n",
       " 'about',\n",
       " 'our',\n",
       " 'lives',\n",
       " 'a',\n",
       " 'disturbing',\n",
       " 'and',\n",
       " 'frighteningly',\n",
       " 'evocative',\n",
       " 'assembly',\n",
       " 'of',\n",
       " 'imagery',\n",
       " 'and',\n",
       " 'hypnotic',\n",
       " 'music',\n",
       " 'composed',\n",
       " 'by',\n",
       " 'philip',\n",
       " 'glass',\n",
       " 'not',\n",
       " 'for',\n",
       " 'everyone',\n",
       " 'but',\n",
       " 'for',\n",
       " 'those',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'it',\n",
       " 'will',\n",
       " 'connect',\n",
       " 'its',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'departure',\n",
       " 'from',\n",
       " 'standard',\n",
       " 'moviegoing',\n",
       " 'fare',\n",
       " 'scores',\n",
       " 'a',\n",
       " 'few',\n",
       " 'points',\n",
       " 'for',\n",
       " 'doing',\n",
       " 'what',\n",
       " 'it',\n",
       " 'does',\n",
       " 'with',\n",
       " 'a',\n",
       " 'dedicated',\n",
       " 'and',\n",
       " 'goodhearted',\n",
       " 'professionalism',\n",
       " 'occasionally',\n",
       " 'melodramatic',\n",
       " 'its',\n",
       " 'also',\n",
       " 'extremely',\n",
       " 'effective',\n",
       " 'spiderman',\n",
       " 'rocks',\n",
       " 'an',\n",
       " 'idealistic',\n",
       " 'love',\n",
       " 'story',\n",
       " 'that',\n",
       " 'brings',\n",
       " 'out',\n",
       " 'the',\n",
       " 'latent',\n",
       " '15yearold',\n",
       " 'romantic',\n",
       " 'in',\n",
       " 'everyone',\n",
       " 'at',\n",
       " 'about',\n",
       " '95',\n",
       " 'minutes',\n",
       " 'treasure',\n",
       " 'planet',\n",
       " 'maintains',\n",
       " 'a',\n",
       " 'brisk',\n",
       " 'pace',\n",
       " 'as',\n",
       " 'it',\n",
       " 'races',\n",
       " 'through',\n",
       " 'the',\n",
       " 'familiar',\n",
       " 'story',\n",
       " 'however',\n",
       " 'it',\n",
       " 'lacks',\n",
       " 'grandeur',\n",
       " 'and',\n",
       " 'that',\n",
       " 'epic',\n",
       " 'quality',\n",
       " 'often',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'stevensons',\n",
       " 'tale',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'with',\n",
       " 'earlier',\n",
       " 'disney',\n",
       " 'efforts',\n",
       " 'it',\n",
       " 'helps',\n",
       " 'that',\n",
       " 'lil',\n",
       " 'bow',\n",
       " 'wow',\n",
       " 'tones',\n",
       " 'down',\n",
       " 'his',\n",
       " 'pintsized',\n",
       " 'gangsta',\n",
       " 'act',\n",
       " 'to',\n",
       " 'play',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'resembles',\n",
       " 'a',\n",
       " 'real',\n",
       " 'kid',\n",
       " 'guaranteed',\n",
       " 'to',\n",
       " 'move',\n",
       " 'anyone',\n",
       " 'who',\n",
       " 'ever',\n",
       " 'shook',\n",
       " 'rattled',\n",
       " 'or',\n",
       " 'rolled',\n",
       " 'a',\n",
       " 'masterful',\n",
       " 'film',\n",
       " 'from',\n",
       " 'a',\n",
       " 'master',\n",
       " 'filmmaker',\n",
       " 'unique',\n",
       " 'in',\n",
       " 'its',\n",
       " 'deceptive',\n",
       " 'grimness',\n",
       " 'compelling',\n",
       " 'in',\n",
       " 'its',\n",
       " 'fatalist',\n",
       " 'worldview',\n",
       " 'light',\n",
       " 'cute',\n",
       " 'and',\n",
       " 'forgettable',\n",
       " 'if',\n",
       " 'theres',\n",
       " 'a',\n",
       " 'way',\n",
       " 'to',\n",
       " 'effectively',\n",
       " 'teach',\n",
       " 'kids',\n",
       " 'about',\n",
       " 'the',\n",
       " 'dangers',\n",
       " 'of',\n",
       " 'drugs',\n",
       " 'i',\n",
       " 'think',\n",
       " 'its',\n",
       " 'in',\n",
       " 'projects',\n",
       " 'like',\n",
       " 'the',\n",
       " 'unfortunately',\n",
       " 'rrated',\n",
       " 'paid',\n",
       " 'while',\n",
       " 'it',\n",
       " 'would',\n",
       " 'be',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'give',\n",
       " 'crush',\n",
       " 'the',\n",
       " 'new',\n",
       " 'title',\n",
       " 'of',\n",
       " 'two',\n",
       " 'weddings',\n",
       " 'and',\n",
       " 'a',\n",
       " 'funeral',\n",
       " 'its',\n",
       " 'a',\n",
       " 'far',\n",
       " 'more',\n",
       " 'thoughtful',\n",
       " 'film',\n",
       " 'than',\n",
       " 'any',\n",
       " 'slice',\n",
       " 'of',\n",
       " 'hugh',\n",
       " 'grant',\n",
       " 'whimsy',\n",
       " 'though',\n",
       " 'everything',\n",
       " 'might',\n",
       " 'be',\n",
       " 'literate',\n",
       " 'and',\n",
       " 'smart',\n",
       " 'it',\n",
       " 'never',\n",
       " 'took',\n",
       " 'off',\n",
       " 'and',\n",
       " 'always',\n",
       " 'seemed',\n",
       " 'static',\n",
       " 'cantet',\n",
       " 'perfectly',\n",
       " 'captures',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'lobbies',\n",
       " 'twolane',\n",
       " 'highways',\n",
       " 'and',\n",
       " 'roadside',\n",
       " 'cafes',\n",
       " 'that',\n",
       " 'permeate',\n",
       " 'vincents',\n",
       " 'days',\n",
       " 'ms',\n",
       " 'fulfordwierzbicki',\n",
       " 'is',\n",
       " 'almost',\n",
       " 'spooky',\n",
       " 'in',\n",
       " 'her',\n",
       " 'sulky',\n",
       " 'calculating',\n",
       " 'lolita',\n",
       " 'turn',\n",
       " 'though',\n",
       " 'it',\n",
       " 'is',\n",
       " 'by',\n",
       " 'no',\n",
       " 'means',\n",
       " 'his',\n",
       " 'best',\n",
       " 'work',\n",
       " 'laissezpasser',\n",
       " 'is',\n",
       " 'a',\n",
       " 'distinguished',\n",
       " 'and',\n",
       " 'distinctive',\n",
       " 'effort',\n",
       " 'by',\n",
       " 'a',\n",
       " 'bonafide',\n",
       " 'master',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'film',\n",
       " 'replete',\n",
       " 'with',\n",
       " 'rewards',\n",
       " 'to',\n",
       " 'be',\n",
       " 'had',\n",
       " 'by',\n",
       " 'all',\n",
       " 'willing',\n",
       " 'to',\n",
       " 'make',\n",
       " 'the',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'reap',\n",
       " 'them',\n",
       " 'like',\n",
       " 'most',\n",
       " 'bond',\n",
       " 'outings',\n",
       " 'in',\n",
       " 'recent',\n",
       " 'years',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'stunts',\n",
       " 'are',\n",
       " 'so',\n",
       " 'outlandish',\n",
       " 'that',\n",
       " 'they',\n",
       " 'border',\n",
       " 'on',\n",
       " 'being',\n",
       " 'cartoonlike',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'reliance',\n",
       " 'on',\n",
       " 'cgi',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'creep',\n",
       " 'into',\n",
       " 'the',\n",
       " 'series',\n",
       " 'newton',\n",
       " 'draws',\n",
       " 'our',\n",
       " 'attention',\n",
       " 'like',\n",
       " 'a',\n",
       " 'magnet',\n",
       " 'and',\n",
       " 'acts',\n",
       " 'circles',\n",
       " 'around',\n",
       " 'her',\n",
       " 'better',\n",
       " 'known',\n",
       " 'costar',\n",
       " 'mark',\n",
       " 'wahlberg',\n",
       " 'the',\n",
       " 'story',\n",
       " 'loses',\n",
       " 'its',\n",
       " 'bite',\n",
       " 'in',\n",
       " 'a',\n",
       " 'lastminute',\n",
       " 'happy',\n",
       " 'ending',\n",
       " 'thats',\n",
       " 'even',\n",
       " 'less',\n",
       " 'plausible',\n",
       " 'than',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'picture',\n",
       " 'much',\n",
       " 'of',\n",
       " 'the',\n",
       " 'way',\n",
       " 'though',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'refreshingly',\n",
       " 'novel',\n",
       " 'ride',\n",
       " 'fuller',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'have',\n",
       " 'called',\n",
       " 'this',\n",
       " 'gutsy',\n",
       " 'and',\n",
       " 'at',\n",
       " 'times',\n",
       " 'exhilarating',\n",
       " 'movie',\n",
       " 'a',\n",
       " 'great',\n",
       " 'yarn',\n",
       " 'compleja',\n",
       " 'e',\n",
       " 'intelectualmente',\n",
       " 'retadora',\n",
       " 'el',\n",
       " 'ladrón',\n",
       " 'de',\n",
       " 'orquídeas',\n",
       " 'es',\n",
       " 'uno',\n",
       " 'de',\n",
       " 'esos',\n",
       " 'filmes',\n",
       " 'que',\n",
       " 'vale',\n",
       " 'la',\n",
       " 'pena',\n",
       " 'ver',\n",
       " 'precisamente',\n",
       " 'por',\n",
       " 'su',\n",
       " 'originalidad',\n",
       " 'the',\n",
       " 'film',\n",
       " 'makes',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'case',\n",
       " 'for',\n",
       " 'the',\n",
       " 'importance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'musicians',\n",
       " 'in',\n",
       " 'creating',\n",
       " 'the',\n",
       " 'motown',\n",
       " 'sound',\n",
       " 'karmen',\n",
       " 'moves',\n",
       " 'like',\n",
       " 'rhythm',\n",
       " 'itself',\n",
       " 'her',\n",
       " 'lips',\n",
       " 'chanting',\n",
       " 'to',\n",
       " 'the',\n",
       " 'beat',\n",
       " 'her',\n",
       " 'long',\n",
       " 'braided',\n",
       " 'hair',\n",
       " 'doing',\n",
       " 'little',\n",
       " 'to',\n",
       " 'wipe',\n",
       " 'away',\n",
       " 'the',\n",
       " 'jeweled',\n",
       " 'beads',\n",
       " 'of',\n",
       " 'sweat',\n",
       " 'gosling',\n",
       " 'provides',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'performance',\n",
       " 'that',\n",
       " 'dwarfs',\n",
       " 'everything',\n",
       " 'else',\n",
       " 'in',\n",
       " 'the',\n",
       " 'film',\n",
       " 'a',\n",
       " 'real',\n",
       " 'movie',\n",
       " 'about',\n",
       " 'real',\n",
       " 'people',\n",
       " 'that',\n",
       " 'gives',\n",
       " 'us',\n",
       " 'a',\n",
       " 'rare',\n",
       " 'glimpse',\n",
       " 'into',\n",
       " 'a',\n",
       " 'culture',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'tender',\n",
       " 'yet',\n",
       " 'lacerating',\n",
       " 'and',\n",
       " 'darkly',\n",
       " 'funny',\n",
       " 'fable',\n",
       " 'may',\n",
       " 'be',\n",
       " 'spoofing',\n",
       " 'an',\n",
       " 'easy',\n",
       " 'target',\n",
       " 'those',\n",
       " 'old',\n",
       " '50s',\n",
       " 'giant',\n",
       " 'creature',\n",
       " 'features',\n",
       " 'but',\n",
       " 'it',\n",
       " 'acknowledges',\n",
       " 'and',\n",
       " 'celebrates',\n",
       " 'their',\n",
       " 'cheesiness',\n",
       " 'as',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'why',\n",
       " 'people',\n",
       " 'get',\n",
       " 'a',\n",
       " 'kick',\n",
       " 'out',\n",
       " 'of',\n",
       " 'watching',\n",
       " 'them',\n",
       " 'today',\n",
       " 'an',\n",
       " 'engaging',\n",
       " 'overview',\n",
       " 'of',\n",
       " 'johnsons',\n",
       " 'eccentric',\n",
       " 'career',\n",
       " 'in',\n",
       " 'its',\n",
       " 'ragged',\n",
       " 'cheap',\n",
       " 'and',\n",
       " 'unassuming',\n",
       " 'way',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'works',\n",
       " 'some',\n",
       " 'actors',\n",
       " 'have',\n",
       " 'so',\n",
       " 'much',\n",
       " 'charisma',\n",
       " 'that',\n",
       " 'youd',\n",
       " 'be',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'them',\n",
       " 'reading',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'book',\n",
       " 'hugh',\n",
       " 'grant',\n",
       " 'and',\n",
       " 'sandra',\n",
       " 'bullock',\n",
       " 'are',\n",
       " 'two',\n",
       " 'such',\n",
       " 'likeable',\n",
       " 'actors',\n",
       " 'sandra',\n",
       " 'nettelbeck',\n",
       " 'beautifully',\n",
       " 'orchestrates',\n",
       " 'the',\n",
       " 'transformation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'chilly',\n",
       " 'neurotic',\n",
       " 'and',\n",
       " 'selfabsorbed',\n",
       " 'martha',\n",
       " 'as',\n",
       " 'her',\n",
       " 'heart',\n",
       " 'begins',\n",
       " 'to',\n",
       " 'open',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'snow',\n",
       " 'games',\n",
       " 'and',\n",
       " 'lovable',\n",
       " 'siberian',\n",
       " 'huskies',\n",
       " 'plus',\n",
       " 'one',\n",
       " 'sheep',\n",
       " 'dog',\n",
       " 'the',\n",
       " 'picture',\n",
       " 'hosts',\n",
       " 'a',\n",
       " 'parkawrapped',\n",
       " 'dose',\n",
       " 'of',\n",
       " 'heart',\n",
       " 'everytime',\n",
       " 'you',\n",
       " 'think',\n",
       " 'undercover',\n",
       " 'brother',\n",
       " 'has',\n",
       " 'run',\n",
       " 'out',\n",
       " 'of',\n",
       " 'steam',\n",
       " 'it',\n",
       " 'finds',\n",
       " 'a',\n",
       " 'new',\n",
       " 'way',\n",
       " 'to',\n",
       " 'surprise',\n",
       " 'and',\n",
       " 'amuse',\n",
       " 'manages',\n",
       " 'to',\n",
       " 'be',\n",
       " 'original',\n",
       " 'even',\n",
       " 'though',\n",
       " 'it',\n",
       " 'rips',\n",
       " 'off',\n",
       " 'many',\n",
       " 'of',\n",
       " 'its',\n",
       " 'ideas',\n",
       " 'singercomposer',\n",
       " 'bryan',\n",
       " 'adams',\n",
       " 'contributes',\n",
       " 'a',\n",
       " 'slew',\n",
       " 'of',\n",
       " 'songs',\n",
       " '\\x97',\n",
       " 'a',\n",
       " 'few',\n",
       " ...]"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_all\n",
    "all_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "mr_all[\"label\"] = le.fit_transform(mr_all[\"label\"])  # Now 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "10657    0\n",
       "10658    0\n",
       "10659    0\n",
       "10660    0\n",
       "10661    0\n",
       "Name: label, Length: 10662, dtype: int64"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_all[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(word_counts.most_common())}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 20494)"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"<PAD>\"], vocab[\"<UNK>\"], len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_ids(tokens, vocab):\n",
    "    return [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "\n",
    "mr_all[\"token_ids\"] = mr_all[\"tokens\"].apply(lambda tokens: tokens_to_ids(tokens, vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, rock, is, destined, to, be, the, 21st, c...</td>\n",
       "      <td>[2, 644, 7, 2540, 6, 20, 2, 3243, 10291, 95, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, gorgeously, elaborate, continuation, of,...</td>\n",
       "      <td>[2, 3244, 2070, 7137, 5, 2, 4500, 5, 2, 2847, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "      <td>[effective, but, tootepid, biopic]</td>\n",
       "      <td>[673, 13, 10295, 1904]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[if, you, sometimes, like, to, go, to, the, mo...</td>\n",
       "      <td>[38, 22, 246, 28, 6, 192, 6, 2, 67, 6, 36, 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[emerges, as, something, rare, an, issue, movi...</td>\n",
       "      <td>[1321, 12, 100, 377, 18, 1759, 19, 109, 37, 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>this picture is murder by numbers , and as eas...</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, picture, is, murder, by, numbers, and, ...</td>\n",
       "      <td>[16, 164, 7, 820, 24, 1317, 4, 12, 378, 6, 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>hilarious musical comedy though stymied by acc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hilarious, musical, comedy, though, stymied, ...</td>\n",
       "      <td>[472, 1347, 55, 132, 20491, 24, 2912, 2254, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>if you are into splatter movies , then you wil...</td>\n",
       "      <td>0</td>\n",
       "      <td>[if, you, are, into, splatter, movies, then, y...</td>\n",
       "      <td>[38, 22, 30, 45, 20492, 67, 211, 22, 54, 326, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>a dull , simple-minded and stereotypical tale ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, dull, simpleminded, and, stereotypical, ta...</td>\n",
       "      <td>[3, 268, 4467, 4, 3752, 168, 5, 1911, 444, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>the feature-length stretch . . . strains the s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, featurelength, stretch, strains, the, sh...</td>\n",
       "      <td>[2, 2274, 6800, 3576, 2, 414, 614]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10662 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      the rock is destined to be the 21st century's ...      1   \n",
       "1      the gorgeously elaborate continuation of \" the...      1   \n",
       "2                         effective but too-tepid biopic      1   \n",
       "3      if you sometimes like to go to the movies to h...      1   \n",
       "4      emerges as something rare , an issue movie tha...      1   \n",
       "...                                                  ...    ...   \n",
       "10657  this picture is murder by numbers , and as eas...      0   \n",
       "10658  hilarious musical comedy though stymied by acc...      0   \n",
       "10659  if you are into splatter movies , then you wil...      0   \n",
       "10660  a dull , simple-minded and stereotypical tale ...      0   \n",
       "10661  the feature-length stretch . . . strains the s...      0   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [the, rock, is, destined, to, be, the, 21st, c...   \n",
       "1      [the, gorgeously, elaborate, continuation, of,...   \n",
       "2                     [effective, but, tootepid, biopic]   \n",
       "3      [if, you, sometimes, like, to, go, to, the, mo...   \n",
       "4      [emerges, as, something, rare, an, issue, movi...   \n",
       "...                                                  ...   \n",
       "10657  [this, picture, is, murder, by, numbers, and, ...   \n",
       "10658  [hilarious, musical, comedy, though, stymied, ...   \n",
       "10659  [if, you, are, into, splatter, movies, then, y...   \n",
       "10660  [a, dull, simpleminded, and, stereotypical, ta...   \n",
       "10661  [the, featurelength, stretch, strains, the, sh...   \n",
       "\n",
       "                                               token_ids  \n",
       "0      [2, 644, 7, 2540, 6, 20, 2, 3243, 10291, 95, 7...  \n",
       "1      [2, 3244, 2070, 7137, 5, 2, 4500, 5, 2, 2847, ...  \n",
       "2                                 [673, 13, 10295, 1904]  \n",
       "3      [38, 22, 246, 28, 6, 192, 6, 2, 67, 6, 36, 127...  \n",
       "4      [1321, 12, 100, 377, 18, 1759, 19, 109, 37, 50...  \n",
       "...                                                  ...  \n",
       "10657  [16, 164, 7, 820, 24, 1317, 4, 12, 378, 6, 20,...  \n",
       "10658  [472, 1347, 55, 132, 20491, 24, 2912, 2254, 12...  \n",
       "10659  [38, 22, 30, 45, 20492, 67, 211, 22, 54, 326, ...  \n",
       "10660  [3, 268, 4467, 4, 3752, 168, 5, 1911, 444, 4, ...  \n",
       "10661                 [2, 2274, 6800, 3576, 2, 414, 614]  \n",
       "\n",
       "[10662 rows x 4 columns]"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Convert to list of tensors\n",
    "sequence_tensors = [torch.tensor(seq) for seq in mr_all[\"token_ids\"]]\n",
    "\n",
    "# Pad\n",
    "padded_seqs = pad_sequence(sequence_tensors, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "label_tensor = torch.tensor(mr_all[\"label\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,   644,     7,  ...,     0,     0,     0],\n",
       "        [    2,  3244,  2070,  ...,     0,     0,     0],\n",
       "        [  673,    13, 10295,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   38,    22,    30,  ...,     0,     0,     0],\n",
       "        [    3,   268,  4467,  ...,     0,     0,     0],\n",
       "        [    2,  2274,  6800,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, padded_seqs, labels):\n",
    "        self.seqs = padded_seqs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seqs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume `padded_seqs` and `label_tensor` are torch.Tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_seqs, label_tensor, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4004, 1169,  404,  ...,    0,    0,    0],\n",
       "        [8402,  856,    2,  ...,    0,    0,    0],\n",
       "        [  51,    2, 1070,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1478, 2758, 2233,  ...,    0,    0,    0],\n",
       "        [  18, 1678, 2361,  ...,    0,    0,    0],\n",
       "        [  10, 6946,    5,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(X_train, y_train)\n",
    "test_dataset = ReviewDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ReviewDataset at 0x7fcde0827130>"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# train_dataset = TensorDataset(X_train, y_train)\n",
    "# test_dataset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)                          # [batch, seq_len, embed_dim]\n",
    "        _, (hidden, _) = self.lstm(embedded)                  # hidden: [2, batch, hidden_dim]\n",
    "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)   # [batch, hidden_dim * 2]\n",
    "        output = self.dropout(hidden)\n",
    "        return self.fc(output)                                # [batch, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMClassifier(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embedding_dim=128,\n",
    "#     hidden_dim=256,\n",
    "#     output_dim=1,\n",
    "#     pad_idx=vocab[\"<PAD>\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StackedBiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        # Because of bidirection, final hidden state will have shape [2 * hidden_dim]\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # [batch, seq_len, embed_dim]\n",
    "        \n",
    "        # Pass through LSTM: get hidden states from last layer\n",
    "        _, (hidden, _) = self.lstm(embedded)  # hidden: [num_layers * 2, batch, hidden_dim]\n",
    "        \n",
    "        # Concatenate the final forward and backward hidden states from the top LSTM layer\n",
    "        hidden_fwd = hidden[-2, :, :]  # Last forward layer\n",
    "        hidden_bwd = hidden[-1, :, :]  # Last backward layer\n",
    "        hidden_cat = torch.cat((hidden_fwd, hidden_bwd), dim=1)  # [batch, hidden_dim * 2]\n",
    "\n",
    "        output = self.dropout(hidden_cat)\n",
    "        return self.fc(output)  # [batch, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackedBiLSTMClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    output_dim=1,\n",
    "    pad_idx=vocab[\"<PAD>\"],\n",
    "    num_layers=4,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedBiLSTMClassifier(\n",
       "  (embedding): Embedding(20494, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 256, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded = torch.round(torch.sigmoid(preds))  # sigmoid to get 0–1\n",
    "    correct = (rounded == y).float()\n",
    "    return correct.sum() / len(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x).squeeze(1)  # [batch]\n",
    "        loss = criterion(preds, y)\n",
    "        acc = binary_accuracy(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device).float()\n",
    "            preds = model(x).squeeze(1)\n",
    "            loss = criterion(preds, y)\n",
    "            acc = binary_accuracy(preds, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedBiLSTMClassifier(\n",
       "  (embedding): Embedding(20494, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 256, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 0.0216 | Train Acc: 99.47%\n",
      "Epoch 2:\n",
      "  Train Loss: 0.0166 | Train Acc: 99.61%\n",
      "Epoch 3:\n",
      "  Train Loss: 0.0149 | Train Acc: 99.73%\n",
      "Epoch 4:\n",
      "  Train Loss: 0.0290 | Train Acc: 99.26%\n",
      "Epoch 5:\n",
      "  Train Loss: 0.0175 | Train Acc: 99.67%\n",
      "Epoch 6:\n",
      "  Train Loss: 0.0312 | Train Acc: 99.27%\n",
      "Epoch 7:\n",
      "  Train Loss: 0.0186 | Train Acc: 99.60%\n",
      "Epoch 8:\n",
      "  Train Loss: 0.0216 | Train Acc: 99.50%\n",
      "Epoch 9:\n",
      "  Train Loss: 0.0080 | Train Acc: 99.87%\n",
      "Epoch 10:\n",
      "  Train Loss: 0.0109 | Train Acc: 99.80%\n",
      "Epoch 11:\n",
      "  Train Loss: 0.0172 | Train Acc: 99.52%\n",
      "Epoch 12:\n",
      "  Train Loss: 0.0131 | Train Acc: 99.61%\n",
      "Epoch 13:\n",
      "  Train Loss: 0.0089 | Train Acc: 99.82%\n",
      "Epoch 14:\n",
      "  Train Loss: 0.0226 | Train Acc: 99.36%\n",
      "Epoch 15:\n",
      "  Train Loss: 0.0048 | Train Acc: 99.92%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    #val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    #print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc*100:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7711 | Test Acc: 72.24%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I love this movie, it was not bad at all, as others say! The performance of the main actor was terrific, and the plot was nigger.\"\n",
    "tokens = preprocess_text(sentence, remove_stopwords=False)\n",
    "token_ids = tokens_to_ids(tokens, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41,\n",
       " 85,\n",
       " 16,\n",
       " 19,\n",
       " 11,\n",
       " 92,\n",
       " 23,\n",
       " 82,\n",
       " 31,\n",
       " 34,\n",
       " 12,\n",
       " 589,\n",
       " 245,\n",
       " 2,\n",
       " 149,\n",
       " 5,\n",
       " 2,\n",
       " 1406,\n",
       " 447,\n",
       " 92,\n",
       " 471,\n",
       " 4,\n",
       " 2,\n",
       " 114,\n",
       " 92,\n",
       " 1]"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0)  # shape: (1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedBiLSTMClassifier(\n",
       "  (embedding): Embedding(20494, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 256, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = input_tensor.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6735]], device='cuda:0')"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6622800230979919"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = torch.sigmoid(output).item()\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = int(prob >= 0.5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng20_all = pd.read_csv(\"./data/ng_20_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>\\n   Henry, if I read you correctly, you may b...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>about\\nthem on\\n\\nActually, I thought Macs wer...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I sent a version of this post out a while ago,...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>I have this kit which includes the following :...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>\\nFine, but one of the points of this entire d...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I was wondering if anyone out there could enli...      7   \n",
       "1      A fair number of brave souls who upgraded thei...      4   \n",
       "2      well folks, my mac plus finally gave up the gh...      4   \n",
       "3      \\nDo you have Weitek's address/phone number?  ...      1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...     14   \n",
       "...                                                  ...    ...   \n",
       "18841  \\n   Henry, if I read you correctly, you may b...     14   \n",
       "18842  about\\nthem on\\n\\nActually, I thought Macs wer...      4   \n",
       "18843  I sent a version of this post out a while ago,...      9   \n",
       "18844  I have this kit which includes the following :...      6   \n",
       "18845  \\nFine, but one of the points of this entire d...     15   \n",
       "\n",
       "                   label_text  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "2       comp.sys.mac.hardware  \n",
       "3               comp.graphics  \n",
       "4                   sci.space  \n",
       "...                       ...  \n",
       "18841               sci.space  \n",
       "18842   comp.sys.mac.hardware  \n",
       "18843      rec.sport.baseball  \n",
       "18844            misc.forsale  \n",
       "18845  soc.religion.christian  \n",
       "\n",
       "[18846 rows x 3 columns]"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng20_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>\\n   Henry, if I read you correctly, you may b...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>about\\nthem on\\n\\nActually, I thought Macs wer...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I sent a version of this post out a while ago,...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>I have this kit which includes the following :...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>\\nFine, but one of the points of this entire d...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I was wondering if anyone out there could enli...      7   \n",
       "1      A fair number of brave souls who upgraded thei...      4   \n",
       "2      well folks, my mac plus finally gave up the gh...      4   \n",
       "3      \\nDo you have Weitek's address/phone number?  ...      1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...     14   \n",
       "...                                                  ...    ...   \n",
       "18841  \\n   Henry, if I read you correctly, you may b...     14   \n",
       "18842  about\\nthem on\\n\\nActually, I thought Macs wer...      4   \n",
       "18843  I sent a version of this post out a while ago,...      9   \n",
       "18844  I have this kit which includes the following :...      6   \n",
       "18845  \\nFine, but one of the points of this entire d...     15   \n",
       "\n",
       "                   label_text  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "2       comp.sys.mac.hardware  \n",
       "3               comp.graphics  \n",
       "4                   sci.space  \n",
       "...                       ...  \n",
       "18841               sci.space  \n",
       "18842   comp.sys.mac.hardware  \n",
       "18843      rec.sport.baseball  \n",
       "18844            misc.forsale  \n",
       "18845  soc.religion.christian  \n",
       "\n",
       "[18846 rows x 3 columns]"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng20_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[762], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ng20_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mng20_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_stopwords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4811\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/baka/experiments/env/lib/python3.10/site-packages/pandas/core/apply.py:1491\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[706], line 2\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text, remove_stopwords)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_text\u001b[39m(text, remove_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()  \u001b[38;5;66;03m# Lowercase\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ch \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation])  \u001b[38;5;66;03m# Remove punctuation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()  \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "ng20_all[\"tokens\"] = ng20_all[\"text\"].apply(preprocess_text, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ng20_all[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ng20_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# what data type is column \"text\" in ng20_all\u001b[39;00m\n\u001b[1;32m      3\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m ng20_all[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mtype\u001b[39m(row) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[39mprint\u001b[39m(i, row)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ng20_all' is not defined"
     ]
    }
   ],
   "source": [
    "# what data type is column \"text\" in ng20_all\n",
    "\n",
    "i = 0\n",
    "for row in ng20_all[0:5][\"text\"]:\n",
    "\n",
    "    if not type(row) == str:\n",
    "        print(i, row)\n",
    "    i+= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
